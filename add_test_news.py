#!/usr/bin/env python3
"""
æ·»åŠ æµ‹è¯•æ–°é—»æ•°æ®ï¼ŒåŒ…å«"æ•°æ®æ³„éœ²"å…³é”®è¯
"""
import asyncio
from datetime import datetime, timedelta
from database import DatabaseManager
import uuid

async def add_test_news():
    """æ·»åŠ æµ‹è¯•æ–°é—»æ•°æ®"""
    
    # åˆå§‹åŒ–æ•°æ®åº“
    db_manager = DatabaseManager()
    await db_manager.connect()
    
    print("ğŸš€ å¼€å§‹æ·»åŠ æµ‹è¯•æ–°é—»æ•°æ®...")
    
    # åˆ›å»ºåŒ…å«"æ•°æ®æ³„éœ²"å…³é”®è¯çš„æµ‹è¯•æ–°é—»
    test_news = [
        {
            "_id": str(uuid.uuid4()),
            "id": f"test_data_leak_{int(datetime.now().timestamp())}001",
            "title": "æŸå¤§å‹ç§‘æŠ€å…¬å¸å‘ç”Ÿä¸¥é‡æ•°æ®æ³„éœ²äº‹ä»¶ï¼Œå½±å“æ•°ç™¾ä¸‡ç”¨æˆ·",
            "pubDate": (datetime.now() - timedelta(hours=2)).strftime("%Y-%m-%d %H:%M:%S"),
            "url": "https://example.com/news/data-leak-001",
            "extra": {"info": False},
            "source_id": "test_source",
            "source_name": "æµ‹è¯•æ–°é—»æº",
            "category": "technology",
            "priority": 1,
            "collected_at": datetime.now(),
            "created_at": datetime.now(),
            "date": datetime.now().strftime("%Y-%m-%d")
        },
        {
            "_id": str(uuid.uuid4()),
            "id": f"test_data_leak_{int(datetime.now().timestamp())}002",
            "title": "ç½‘ç»œå®‰å…¨ä¸“å®¶è­¦å‘Šï¼šæ•°æ®æ³„éœ²äº‹ä»¶é¢‘å‘ï¼Œä¼ä¸šéœ€åŠ å¼ºé˜²æŠ¤",
            "pubDate": (datetime.now() - timedelta(hours=4)).strftime("%Y-%m-%d %H:%M:%S"),
            "url": "https://example.com/news/data-leak-002",
            "extra": {"info": False},
            "source_id": "test_source",
            "source_name": "æµ‹è¯•æ–°é—»æº",
            "category": "technology",
            "priority": 1,
            "collected_at": datetime.now(),
            "created_at": datetime.now(),
            "date": datetime.now().strftime("%Y-%m-%d")
        },
        {
            "_id": str(uuid.uuid4()),
            "id": f"test_data_leak_{int(datetime.now().timestamp())}003",
            "title": "æ”¿åºœéƒ¨é—¨å‘å¸ƒæ•°æ®æ³„éœ²é˜²æŠ¤æ–°è§„å®šï¼Œè¦æ±‚ä¼ä¸šä¸¥æ ¼æ‰§è¡Œ",
            "pubDate": (datetime.now() - timedelta(hours=6)).strftime("%Y-%m-%d %H:%M:%S"),
            "url": "https://example.com/news/data-leak-003",
            "extra": {"info": False},
            "source_id": "test_source",
            "source_name": "æµ‹è¯•æ–°é—»æº",
            "category": "policy",
            "priority": 1,
            "collected_at": datetime.now(),
            "created_at": datetime.now(),
            "date": datetime.now().strftime("%Y-%m-%d")
        },
        {
            "_id": str(uuid.uuid4()),
            "id": f"test_data_leak_{int(datetime.now().timestamp())}004",
            "title": "é“¶è¡Œä¸šæ•°æ®æ³„éœ²æ¡ˆä¾‹åˆ†æï¼šå¦‚ä½•é¿å…å®¢æˆ·ä¿¡æ¯å¤–æ³„",
            "pubDate": (datetime.now() - timedelta(hours=8)).strftime("%Y-%m-%d %H:%M:%S"),
            "url": "https://example.com/news/data-leak-004",
            "extra": {"info": False},
            "source_id": "test_source",
            "source_name": "æµ‹è¯•æ–°é—»æº",
            "category": "finance",
            "priority": 1,
            "collected_at": datetime.now(),
            "created_at": datetime.now(),
            "date": datetime.now().strftime("%Y-%m-%d")
        },
        {
            "_id": str(uuid.uuid4()),
            "id": f"test_data_leak_{int(datetime.now().timestamp())}005",
            "title": "å›½é™…æ•°æ®æ³„éœ²äº‹ä»¶å›é¡¾ï¼š2024å¹´åå¤§å®‰å…¨äº‹æ•…ç›˜ç‚¹",
            "pubDate": (datetime.now() - timedelta(hours=12)).strftime("%Y-%m-%d %H:%M:%S"),
            "url": "https://example.com/news/data-leak-005",
            "extra": {"info": False},
            "source_id": "test_source",
            "source_name": "æµ‹è¯•æ–°é—»æº",
            "category": "technology",
            "priority": 1,
            "collected_at": datetime.now(),
            "created_at": datetime.now(),
            "date": datetime.now().strftime("%Y-%m-%d")
        }
    ]
    
    # æ’å…¥æµ‹è¯•æ•°æ®
    result = await db_manager.insert_data(test_news)
    
    if result:
        print(f"âœ… æˆåŠŸæ·»åŠ  {len(test_news)} æ¡åŒ…å«'æ•°æ®æ³„éœ²'å…³é”®è¯çš„æµ‹è¯•æ–°é—»")
        
        # éªŒè¯æ•°æ®æ˜¯å¦æ’å…¥æˆåŠŸ
        search_result, total = await db_manager.search_data(keyword="æ•°æ®æ³„éœ²", limit=10)
        print(f"âœ… éªŒè¯ï¼šç°åœ¨æ•°æ®åº“ä¸­æœ‰ {total} æ¡åŒ…å«'æ•°æ®æ³„éœ²'çš„æ–°é—»")
        
        for i, news in enumerate(search_result[:3], 1):
            print(f"   {i}. {news.get('title', 'N/A')}")
    else:
        print("âŒ æ·»åŠ æµ‹è¯•æ•°æ®å¤±è´¥")
    
    # å…³é—­è¿æ¥
    await db_manager.close()
    print("ğŸ‰ æµ‹è¯•æ•°æ®æ·»åŠ å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(add_test_news())
